<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Projects — GEONMIN LEE</title>
  <meta name="description" content="Projects by GEONMIN LEE">
  <meta name="theme-color" content="#2563EB">
  <meta property="og:title" content="Projects — GEONMIN LEE">
  <meta property="og:description" content="Projects by GEONMIN LEE">
  <meta property="og:type" content="website">
  <meta property="og:image" content="/assets/img/og.png">
  <link rel="icon" href="/favicon.svg" type="image/svg+xml">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Noto+Sans+KR:wght@400;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/assets/css/style.css">
  <script defer src="/assets/js/main.js"></script>
</head>
<body>
<header class="site-header">
  <div class="container nav">
    <a class="brand" href="/"><span class="brand-strong">GEONMIN</span> <span class="brand-faint">LEE</span></a>
    <nav class="menu" id="menu">
      <a href="/projects.html">Projects</a>
      <a href="/about.html">About</a>
      <a href="/blog.html">Blog</a>
      <a class="btn" href="mailto:contact@example.com">Contact</a>
      <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">🌓</button>
    </nav>
    <button class="hamburger" id="hamburger" aria-label="Open menu">☰</button>
  </div>
</header>
<main class="container section">
  <div class="section-head">
    <h1>Projects</h1>
    <p>일일 업무 메모(2023-01-19 ~ 2025-10-17)를 기반으로 자동 집계한 프로젝트 묶음입니다. 각 카드 클릭 시 상세 섹션으로 이동합니다.</p>
  </div>

  <div class="filters">
    <button class="chip active" data-tag="all">All</button>
    <button class="chip" data-tag="vlm">VLM</button>
    <button class="chip" data-tag="ocr">OCR</button>
    <button class="chip" data-tag="retrieval">Retrieval</button>
    <button class="chip" data-tag="nlp">NLP</button>
  </div>
<div class="grid projects-grid">

    <article class="card" data-tags="nlp">
      <a href="#word2vec-synonym-dictionary-nlp-pre-2024">
        <img src="/assets/img/project1.svg" alt="Word2Vec Synonym Dictionary / NLP Pre-2024">
        <h3>Word2Vec Synonym Dictionary / NLP Pre-2024</h3>
        <p>검증/샘플링; 도메인 유의어 사전 구축 — 유의어 정확도 향상</p>
        <p class="meta">2023.02.06 – 2025.10.16</p>
      </a>
    </article>

    <article class="card" data-tags="ocr">
      <a href="#document-ai-table-html-extraction">
        <img src="/assets/img/project1.svg" alt="Document AI — Table HTML Extraction">
        <h3>Document AI — Table HTML Extraction</h3>
        <p>HTML 스키마/토큰 규칙 설계; 평가 스크립트(구조/텍스트) 작성 — 구조 정확도 향상, 빈 셀/rowspan/colspan 오류 감소</p>
        <p class="meta">2023.02.15 – 2025.10.17</p>
      </a>
    </article>

    <article class="card" data-tags="vlm">
      <a href="#mermaid-diagram-generation-pipeline">
        <img src="/assets/img/project2.svg" alt="Mermaid Diagram Generation Pipeline">
        <h3>Mermaid Diagram Generation Pipeline</h3>
        <p>렌더링 오류 자동 검출; 재프롬프트/정규화 루틴 — Fence/문법 오류 감소, 타입별 정확도 개선</p>
        <p class="meta">2023.03.17 – 2025.10.17</p>
      </a>
    </article>

    <article class="card" data-tags="vlm">
      <a href="#qwen-series-fine-tuning-qwen2-5-vl-qwen3-vl-">
        <img src="/assets/img/project1.svg" alt="Qwen-series Fine-Tuning (Qwen2.5-VL / Qwen3-VL)">
        <h3>Qwen-series Fine-Tuning (Qwen2.5-VL / Qwen3-VL)</h3>
        <p>Attention/토큰 시각화; QLoRA 실험/하이퍼파라미터 튜닝 — Vision Prior 강화, 32B 모델 추론 파이프라인 구축</p>
        <p class="meta">2023.04.14 – 2025.10.17</p>
      </a>
    </article>

    <article class="card" data-tags="retrieval">
      <a href="#any-to-any-embedding-retrieval">
        <img src="/assets/img/project3.svg" alt="Any-to-Any Embedding & Retrieval">
        <h3>Any-to-Any Embedding & Retrieval</h3>
        <p>Query-centric 평가; 세그먼트 스키마 설계 — 검색 정확도/속도 개선</p>
        <p class="meta">2023.09.04 – 2025.10.17</p>
      </a>
    </article>

    <article class="card" data-tags="vlm">
      <a href="#fastvithd-qwen-fusion">
        <img src="/assets/img/project1.svg" alt="FastViTHD + Qwen Fusion">
        <h3>FastViTHD + Qwen Fusion</h3>
        <p>Attention/토큰 시각화; Fusion 아키텍처 설계 — Vision Prior 강화, 32B 모델 추론 파이프라인 구축, 프로토타입 학습 스크립트 완성</p>
        <p class="meta">2024.05.13 – 2025.10.17</p>
      </a>
    </article>
</div>
</main>
<section class="container section prose" id="word2vec-synonym-dictionary-nlp-pre-2024">
<h2>Word2Vec Synonym Dictionary / NLP Pre-2024</h2>
<p><strong>기간:</strong> 2023.02.06 – 2025.10.16 · <strong>파일 수:</strong> 188</p>
<p><strong>역할:</strong> 검증/샘플링, 도메인 유의어 사전 구축, 형태소 분석 파이프라인</p>
<p><strong>기술 스택:</strong> KoNLPy, MeCab/OKT, Python, gensim</p>
<p><strong>성과:</strong> 유의어 정확도 향상</p>
<ul>
<li><strong>상위 키워드:</strong> tokenizer×583, 사전×190, word2vec×109, 형태소×48, postag×40, mecab×23, 유의어×9, okt×1</li>
</ul>
<h3>상세 메모(발췌)</h3><ul>
<li>* Word2Vec - 유의어 사전 만들기 *</li>
<li>with open('word2vec_sentence_postag_test.pickle', 'rb') as p:</li>
<li># -> 현재 results는 이중리스트! [ [첫 번째  문장], [두 번째 문장], ... ] -> (각 문장은 단어별로 형태소 분석(+개체명인식)이 되어 있는 상태) // type : list</li>
<li>t: [('관세법', 'NNG', '*'), ('제', 'XPN', '*'), ('37', 'SN', '*'), ('조제', 'NNG', '행위'), ('1', 'SN', '*'), ('항', 'NNG', '*'), ('제', 'XPN', '*'), ('3', 'SN', '*'), ('호', 'NNBC', '*'), ('에', 'JKB', '*'), ('따…</li>
<li>from gensim.models import Word2Vec</li>
<li>with open('word2vec_rawdata.pickle', 'rb') as p:</li>
<li># 형태소 분리 및 형태소태그 부착</li>
<li>postag_data = get_posdata(nori_analyzer, raw_data)</li>
<li>if postag_data:</li>
<li>results.append(postag_data)</li>
</ul>
</section>
<section class="container section prose" id="document-ai-table-html-extraction">
<h2>Document AI — Table HTML Extraction</h2>
<p><strong>기간:</strong> 2023.02.15 – 2025.10.17 · <strong>파일 수:</strong> 374</p>
<p><strong>역할:</strong> HTML 스키마/토큰 규칙 설계, 평가 스크립트(구조/텍스트) 작성, 표 구조 라벨링/정제</p>
<p><strong>기술 스택:</strong> Evaluation Scripts, Pandas, Python, Qwen2.5-VL, Regex</p>
<p><strong>성과:</strong> 구조 정확도 향상, 빈 셀/rowspan/colspan 오류 감소</p>
<ul>
<li><strong>상위 키워드:</strong> table×2889, 셀×1198, ocr×897, colspan×688, rowspan×686, structure×505, <table>×314, 테이블×296, 표 구조×82, html table×9</li>
</ul>
<h3>상세 메모(발췌)</h3><ul>
<li>update 스키마.테이블명</li>
<li>1. File-Project Structure > Project SDK와 Project language level을 프로젝트 버전에 맞게 변경</li>
<li>-> Project Structure > Project Settings > Project</li>
<li>-> 불용 개체명 제외 후 DB에 insert하면 Table - related_word(keyword, related_word, flag, score, created_at)에서 확인 가능</li>
<li>-> 불용 개체명 제외 후 DB에 insert하면 Table - related_word(keyword, related_word, flag, score, created_at)에서 확인 가능</li>
<li>1. 챗지피티 사이트 ui 테스트 -> 인풋 아웃풋 프롬프트 엑셀이나 피피티</li>
<li>table: related_word에 keyword='改名'이 들어가서 삭제해야함~</li>
<li>항체의약품은 국립보건연구원과 국내기업(셀트리온)이 공동연구 진행 중으로, 연내 임상시험 진입을 목표로 하여 빠르면 내년 중으로 출시가 가능할 것으로 예상되며,</li>
<li>1.	db > table : file_summary_mnstr  / columns : file_id, ext_summary 10,000건 추출 (최신 날짜부터~)</li>
<li>셀레니움 사용법 업데이트 참고사이트. .</li>
</ul>
</section>
<section class="container section prose" id="mermaid-diagram-generation-pipeline">
<h2>Mermaid Diagram Generation Pipeline</h2>
<p><strong>기간:</strong> 2023.03.17 – 2025.10.17 · <strong>파일 수:</strong> 77</p>
<p><strong>역할:</strong> 렌더링 오류 자동 검출, 재프롬프트/정규화 루틴, 타입 추론 규칙 제작</p>
<p><strong>기술 스택:</strong> Mermaid, OpenAI API, PIL, Python, Regex</p>
<p><strong>성과:</strong> Fence/문법 오류 감소, 타입별 정확도 개선</p>
<ul>
<li><strong>상위 키워드:</strong> mermaid×229, 차트×126, pie×118, xychart×91, flowchart×86, 다이어그램×83, diagram×82</li>
</ul>
<h3>상세 메모(발췌)</h3><ul>
<li>* 구글플레이 최고 매출 차트는 모바일 게임의 흥행여부를 보여주는 주요 지표다.</li>
<li>Recipient</li>
<li>kiwipiepy                 0.16.2                   pypi_0    pypi</li>
<li>kiwipiepy-model       0.16.0                   pypi_0    pypi</li>
<li>from kiwipiepy import Kiwi</li>
<li>prompt.messages[0].prompt.template = "You are an assistant for make some question-answering datasets. Use the following pieces of retrieved context to make datasets.\nQuestion: {question} \nContext: {…</li>
<li>prompt.messages[0].prompt.template = "You are an assistant for make some question-answering datasets. Use the following pieces of retrieved context to make datasets.\nQuestion: {question} \nContext: {…</li>
<li>prompt.messages[0].prompt.template = "You are an assistant for make some question-answering datasets. Use the following pieces of retrieved context to make datasets.\nQuestion: {question} \nContext: {…</li>
<li>의료진은 핵심 개념을 설명하는 데 도움이 되는 그림  다이어그램  또는 차트와 같은 설명을 추가할 수도 있습니다.</li>
<li>또한 기단 모서리에 있는 네 개의 미나렛은 이슬람 건축의 특징입니다.인도의 영향은 차트리(돔 모양의 파빌리온) 연꽃 모티프와 피에트라 두라 기법 즉 반귀석(반귀석)을 석재 기초에 삽입하여 복잡한 꽃 무늬를 만드는 장식 기법에서 볼 수 있습니다.타지마할의 건축 기술도 놀라웠습니다.</li>
</ul>
</section>
<section class="container section prose" id="qwen-series-fine-tuning-qwen2-5-vl-qwen3-vl-">
<h2>Qwen-series Fine-Tuning (Qwen2.5-VL / Qwen3-VL)</h2>
<p><strong>기간:</strong> 2023.04.14 – 2025.10.17 · <strong>파일 수:</strong> 366</p>
<p><strong>역할:</strong> Attention/토큰 시각화, QLoRA 실험/하이퍼파라미터 튜닝, VLM 파인튜닝 설계, 커리큘럼/로스 마스킹</p>
<p><strong>기술 스택:</strong> ClearML, DeepSpeed, LoRA/QLoRA, PyTorch, Qwen2.5-VL, Qwen3-VL, Transformers, vLLM</p>
<p><strong>성과:</strong> Vision Prior 강화, 32B 모델 추론 파이프라인 구축</p>
<ul>
<li><strong>상위 키워드:</strong> clearml×3789, qwen×1769, lora×1245, qwen2.5×928, deepspeed×252, qwen2_5×185, vllm×146, attention×138, projector×99, qwen3×58, freeze×36, qlora×36</li>
</ul>
<h3>상세 메모(발췌)</h3><ul>
<li>{"instruction": "What is a console war in video games?", "context": "In the video game industry, a console war describes the competition between two or more video game console manufacturers in trying …</li>
<li>tactics by each company to try to gain control of the marketplace, and ended around 1995 when a new player, Sony, entered and disrupted the console space.\n\nThe United States video game industry suff…</li>
<li>drwxr-xr-x.  9 aisearch aisearch        4096  8월 21 17:03 alpaca-lora</li>
<li>-rw-rw-r--.  1 aisearch aisearch    99256109  6월 20 10:08 notebooks.lora.tar.gz</li>
<li>alpaca-lora                                                    latest                     d9d48ca7aee4   3 months ago   24.4GB</li>
<li>alpaca-lora                                                    latest                     d9d48ca7aee4   3 months ago   24.4GB</li>
<li>aisearch@urpaigpu1:~$ alpaca-lora                                                    latest                     d9d48ca7aee4   3 months ago   24.4GB</li>
<li>alpaca-lora: command not found</li>
<li>aisearch@urpaigpu1:~$ alpaca-lora                                                    latest                     d9d48ca7aee4   3 months ago   24.4GB</li>
<li>alpaca-lora: command not found</li>
</ul>
</section>
<section class="container section prose" id="any-to-any-embedding-retrieval">
<h2>Any-to-Any Embedding & Retrieval</h2>
<p><strong>기간:</strong> 2023.09.04 – 2025.10.17 · <strong>파일 수:</strong> 121</p>
<p><strong>역할:</strong> Query-centric 평가, 세그먼트 스키마 설계, 임베딩/검색 파이프라인</p>
<p><strong>기술 스택:</strong> FAISS, NumPy, Pandas, Python, Transformers</p>
<p><strong>성과:</strong> 검색 정확도/속도 개선</p>
<ul>
<li><strong>상위 키워드:</strong> embedding×361, similarity×81, faiss×77, retrieval×63, 세그먼트×51, bbox_norm×31, query-centric×12, indexflatip×11</li>
</ul>
<h3>상세 메모(발췌)</h3><ul>
<li>https://www.elastic.co/search-labs/how-to-deploy-nlp-text-embeddings-and-vector-search</li>
<li>https://www.elastic.co/kr/blog/how-to-deploy-nlp-text-embeddings-and-vector-search</li>
<li>https://www.unite.ai/ko/what-is-vector-similarity-search-how-is-it-useful/</li>
<li>임베딩 벡터 생성 후 매핑하기 (id, document_key, embedding_vector)</li>
<li>임베딩 벡터 생성 후 매핑하기 (id, document_key, embedding_vector)</li>
<li>query_embeddings</li>
<li>"cosine_similarity": {</li>
<li>"cosine_similarity": {</li>
<li>query_embeddings</li>
<li>https://www.elastic.co/kr/blog/how-to-deploy-nlp-text-embeddings-and-vector-search</li>
</ul>
</section>
<section class="container section prose" id="fastvithd-qwen-fusion">
<h2>FastViTHD + Qwen Fusion</h2>
<p><strong>기간:</strong> 2024.05.13 – 2025.10.17 · <strong>파일 수:</strong> 34</p>
<p><strong>역할:</strong> Attention/토큰 시각화, Fusion 아키텍처 설계, Projector/PE 주입 실험, QLoRA 실험/하이퍼파라미터 튜닝, VLM 파인튜닝 설계, 커리큘럼/로스 마스킹, 해상도 버킷 캘리브레이션</p>
<p><strong>기술 스택:</strong> ClearML, DeepSpeed, FastViT, LoRA/QLoRA, Projection Layers, PyTorch, Qwen2.5-VL, Qwen3-32B, Qwen3-VL, Transformers, vLLM</p>
<p><strong>성과:</strong> Vision Prior 강화, 32B 모델 추론 파이프라인 구축, 프로토타입 학습 스크립트 완성</p>
<ul>
<li><strong>상위 키워드:</strong> projector×99, vision encoder×59, fusion×35, fastvlm×21, fastvithd×18, apple-style×2, sin/cos×1</li>
</ul>
<h3>상세 메모(발췌)</h3><ul>
<li>{'text_eng': 'The works of what American author include  The Catcher in the Rye   a novel that has become synonymous with teenage rebellion?\nJ.D. Salinger\nWhat significant impact did J.D. Salinger s…</li>
<li>WARN[0000] /home/aisearch/clearml/datasets/document_parse/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion</li>
<li>WARN[0000] /home/aisearch/clearml/datasets/document_parse/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion</li>
<li>WARN[0000] /home/aisearch/clearml/datasets/document_parse/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion</li>
<li>(1) Vision Encoder</li>
<li>print(f"Input size to Vision Encoder: H={H}, W={W}")</li>
<li>비전 인코더(Vision Encoder): 이미지 데이터를 이해하고 특징을 추출하여 언어 모델이 처리할 수 있는 형태로 변환합니다.</li>
<li>(1) Vision Encoder</li>
<li>print(f"Input size to Vision Encoder: H={H}, W={W}")</li>
<li>✅ vision encoder는 freeze</li>
</ul>
</section>
<footer class="site-footer">
  <div class="container">
    <div class="cols">
      <div>
        <h4>About this site</h4>
        <p>Nomod-inspired minimal portfolio. Built with plain HTML/CSS/JS and hosted on GitHub Pages.</p>
      </div>
      <div>
        <h4>Links</h4>
        <ul>
          <li><a href="https://github.com/geonmin0607" target="_blank" rel="noopener">GitHub</a></li>
          <li><a href="mailto:contact@example.com">Email</a></li>
        </ul>
      </div>
      <div>
        <h4>Location</h4>
        <p>Seoul, Korea (UTC+9)</p>
      </div>
    </div>
    <p class="copy">© 2025 GEONMIN LEE. All rights reserved.</p>
  </div>
</footer>
</body>
</html>
