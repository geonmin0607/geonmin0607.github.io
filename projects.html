<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Projects â€” GEONMIN LEE</title>
  <meta name="description" content="Projects by GEONMIN LEE">
  <meta name="theme-color" content="#2563EB">
  <meta property="og:title" content="Projects â€” GEONMIN LEE">
  <meta property="og:description" content="Projects by GEONMIN LEE">
  <meta property="og:type" content="website">
  <meta property="og:image" content="/assets/img/og.png">
  <link rel="icon" href="/favicon.svg" type="image/svg+xml">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Noto+Sans+KR:wght@400;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/assets/css/style.css">
  <script defer src="/assets/js/main.js"></script>
</head>
<body>
<header class="site-header">
  <div class="container nav">
    <a class="brand" href="/"><span class="brand-strong">GEONMIN</span> <span class="brand-faint">LEE</span></a>
    <nav class="menu" id="menu">
      <a href="/projects.html">Projects</a>
      <a href="/about.html">About</a>
      <a href="/blog.html">Blog</a>
      <a class="btn" href="mailto:contact@example.com">Contact</a>
      <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">ğŸŒ“</button>
    </nav>
    <button class="hamburger" id="hamburger" aria-label="Open menu">â˜°</button>
  </div>
</header>
<main class="container section">
  <div class="section-head">
    <h1>Projects</h1>
    <p>ì¼ì¼ ì—…ë¬´ ë©”ëª¨(2023-01-19 ~ 2025-10-17)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ ì§‘ê³„í•œ í”„ë¡œì íŠ¸ ë¬¶ìŒì…ë‹ˆë‹¤. ê° ì¹´ë“œ í´ë¦­ ì‹œ ìƒì„¸ ì„¹ì…˜ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.</p>
  </div>

  <div class="filters">
    <button class="chip active" data-tag="all">All</button>
    <button class="chip" data-tag="vlm">VLM</button>
    <button class="chip" data-tag="ocr">OCR</button>
    <button class="chip" data-tag="retrieval">Retrieval</button>
    <button class="chip" data-tag="nlp">NLP</button>
  </div>
<div class="grid projects-grid">

    <article class="card" data-tags="nlp">
      <a href="#word2vec-synonym-dictionary-nlp-pre-2024">
        <img src="/assets/img/project1.svg" alt="Word2Vec Synonym Dictionary / NLP Pre-2024">
        <h3>Word2Vec Synonym Dictionary / NLP Pre-2024</h3>
        <p>ê²€ì¦/ìƒ˜í”Œë§; ë„ë©”ì¸ ìœ ì˜ì–´ ì‚¬ì „ êµ¬ì¶• â€” ìœ ì˜ì–´ ì •í™•ë„ í–¥ìƒ</p>
        <p class="meta">2023.02.06 â€“ 2025.10.16</p>
      </a>
    </article>

    <article class="card" data-tags="ocr">
      <a href="#document-ai-table-html-extraction">
        <img src="/assets/img/project1.svg" alt="Document AI â€” Table HTML Extraction">
        <h3>Document AI â€” Table HTML Extraction</h3>
        <p>HTML ìŠ¤í‚¤ë§ˆ/í† í° ê·œì¹™ ì„¤ê³„; í‰ê°€ ìŠ¤í¬ë¦½íŠ¸(êµ¬ì¡°/í…ìŠ¤íŠ¸) ì‘ì„± â€” êµ¬ì¡° ì •í™•ë„ í–¥ìƒ, ë¹ˆ ì…€/rowspan/colspan ì˜¤ë¥˜ ê°ì†Œ</p>
        <p class="meta">2023.02.15 â€“ 2025.10.17</p>
      </a>
    </article>

    <article class="card" data-tags="vlm">
      <a href="#mermaid-diagram-generation-pipeline">
        <img src="/assets/img/project2.svg" alt="Mermaid Diagram Generation Pipeline">
        <h3>Mermaid Diagram Generation Pipeline</h3>
        <p>ë Œë”ë§ ì˜¤ë¥˜ ìë™ ê²€ì¶œ; ì¬í”„ë¡¬í”„íŠ¸/ì •ê·œí™” ë£¨í‹´ â€” Fence/ë¬¸ë²• ì˜¤ë¥˜ ê°ì†Œ, íƒ€ì…ë³„ ì •í™•ë„ ê°œì„ </p>
        <p class="meta">2023.03.17 â€“ 2025.10.17</p>
      </a>
    </article>

    <article class="card" data-tags="vlm">
      <a href="#qwen-series-fine-tuning-qwen2-5-vl-qwen3-vl-">
        <img src="/assets/img/project1.svg" alt="Qwen-series Fine-Tuning (Qwen2.5-VL / Qwen3-VL)">
        <h3>Qwen-series Fine-Tuning (Qwen2.5-VL / Qwen3-VL)</h3>
        <p>Attention/í† í° ì‹œê°í™”; QLoRA ì‹¤í—˜/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ â€” Vision Prior ê°•í™”, 32B ëª¨ë¸ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ êµ¬ì¶•</p>
        <p class="meta">2023.04.14 â€“ 2025.10.17</p>
      </a>
    </article>

    <article class="card" data-tags="retrieval">
      <a href="#any-to-any-embedding-retrieval">
        <img src="/assets/img/project3.svg" alt="Any-to-Any Embedding & Retrieval">
        <h3>Any-to-Any Embedding & Retrieval</h3>
        <p>Query-centric í‰ê°€; ì„¸ê·¸ë¨¼íŠ¸ ìŠ¤í‚¤ë§ˆ ì„¤ê³„ â€” ê²€ìƒ‰ ì •í™•ë„/ì†ë„ ê°œì„ </p>
        <p class="meta">2023.09.04 â€“ 2025.10.17</p>
      </a>
    </article>

    <article class="card" data-tags="vlm">
      <a href="#fastvithd-qwen-fusion">
        <img src="/assets/img/project1.svg" alt="FastViTHD + Qwen Fusion">
        <h3>FastViTHD + Qwen Fusion</h3>
        <p>Attention/í† í° ì‹œê°í™”; Fusion ì•„í‚¤í…ì²˜ ì„¤ê³„ â€” Vision Prior ê°•í™”, 32B ëª¨ë¸ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ êµ¬ì¶•, í”„ë¡œí† íƒ€ì… í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì™„ì„±</p>
        <p class="meta">2024.05.13 â€“ 2025.10.17</p>
      </a>
    </article>
</div>
</main>
<section class="container section prose" id="word2vec-synonym-dictionary-nlp-pre-2024">
<h2>Word2Vec Synonym Dictionary / NLP Pre-2024</h2>
<p><strong>ê¸°ê°„:</strong> 2023.02.06 â€“ 2025.10.16 Â· <strong>íŒŒì¼ ìˆ˜:</strong> 188</p>
<p><strong>ì—­í• :</strong> ê²€ì¦/ìƒ˜í”Œë§, ë„ë©”ì¸ ìœ ì˜ì–´ ì‚¬ì „ êµ¬ì¶•, í˜•íƒœì†Œ ë¶„ì„ íŒŒì´í”„ë¼ì¸</p>
<p><strong>ê¸°ìˆ  ìŠ¤íƒ:</strong> KoNLPy, MeCab/OKT, Python, gensim</p>
<p><strong>ì„±ê³¼:</strong> ìœ ì˜ì–´ ì •í™•ë„ í–¥ìƒ</p>
<ul>
<li><strong>ìƒìœ„ í‚¤ì›Œë“œ:</strong> tokenizerÃ—583, ì‚¬ì „Ã—190, word2vecÃ—109, í˜•íƒœì†ŒÃ—48, postagÃ—40, mecabÃ—23, ìœ ì˜ì–´Ã—9, oktÃ—1</li>
</ul>
<h3>ìƒì„¸ ë©”ëª¨(ë°œì·Œ)</h3><ul>
<li>* Word2Vec - ìœ ì˜ì–´ ì‚¬ì „ ë§Œë“¤ê¸° *</li>
<li>with open('word2vec_sentence_postag_test.pickle', 'rb') as p:</li>
<li># -> í˜„ì¬ resultsëŠ” ì´ì¤‘ë¦¬ìŠ¤íŠ¸! [ [ì²« ë²ˆì§¸  ë¬¸ì¥], [ë‘ ë²ˆì§¸ ë¬¸ì¥], ... ] -> (ê° ë¬¸ì¥ì€ ë‹¨ì–´ë³„ë¡œ í˜•íƒœì†Œ ë¶„ì„(+ê°œì²´ëª…ì¸ì‹)ì´ ë˜ì–´ ìˆëŠ” ìƒíƒœ) // type : list</li>
<li>t: [('ê´€ì„¸ë²•', 'NNG', '*'), ('ì œ', 'XPN', '*'), ('37', 'SN', '*'), ('ì¡°ì œ', 'NNG', 'í–‰ìœ„'), ('1', 'SN', '*'), ('í•­', 'NNG', '*'), ('ì œ', 'XPN', '*'), ('3', 'SN', '*'), ('í˜¸', 'NNBC', '*'), ('ì—', 'JKB', '*'), ('ë”°â€¦</li>
<li>from gensim.models import Word2Vec</li>
<li>with open('word2vec_rawdata.pickle', 'rb') as p:</li>
<li># í˜•íƒœì†Œ ë¶„ë¦¬ ë° í˜•íƒœì†Œíƒœê·¸ ë¶€ì°©</li>
<li>postag_data = get_posdata(nori_analyzer, raw_data)</li>
<li>if postag_data:</li>
<li>results.append(postag_data)</li>
</ul>
</section>
<section class="container section prose" id="document-ai-table-html-extraction">
<h2>Document AI â€” Table HTML Extraction</h2>
<p><strong>ê¸°ê°„:</strong> 2023.02.15 â€“ 2025.10.17 Â· <strong>íŒŒì¼ ìˆ˜:</strong> 374</p>
<p><strong>ì—­í• :</strong> HTML ìŠ¤í‚¤ë§ˆ/í† í° ê·œì¹™ ì„¤ê³„, í‰ê°€ ìŠ¤í¬ë¦½íŠ¸(êµ¬ì¡°/í…ìŠ¤íŠ¸) ì‘ì„±, í‘œ êµ¬ì¡° ë¼ë²¨ë§/ì •ì œ</p>
<p><strong>ê¸°ìˆ  ìŠ¤íƒ:</strong> Evaluation Scripts, Pandas, Python, Qwen2.5-VL, Regex</p>
<p><strong>ì„±ê³¼:</strong> êµ¬ì¡° ì •í™•ë„ í–¥ìƒ, ë¹ˆ ì…€/rowspan/colspan ì˜¤ë¥˜ ê°ì†Œ</p>
<ul>
<li><strong>ìƒìœ„ í‚¤ì›Œë“œ:</strong> tableÃ—2889, ì…€Ã—1198, ocrÃ—897, colspanÃ—688, rowspanÃ—686, structureÃ—505, <table>Ã—314, í…Œì´ë¸”Ã—296, í‘œ êµ¬ì¡°Ã—82, html tableÃ—9</li>
</ul>
<h3>ìƒì„¸ ë©”ëª¨(ë°œì·Œ)</h3><ul>
<li>update ìŠ¤í‚¤ë§ˆ.í…Œì´ë¸”ëª…</li>
<li>1. File-Project Structure > Project SDKì™€ Project language levelì„ í”„ë¡œì íŠ¸ ë²„ì „ì— ë§ê²Œ ë³€ê²½</li>
<li>-> Project Structure > Project Settings > Project</li>
<li>-> ë¶ˆìš© ê°œì²´ëª… ì œì™¸ í›„ DBì— insertí•˜ë©´ Table - related_word(keyword, related_word, flag, score, created_at)ì—ì„œ í™•ì¸ ê°€ëŠ¥</li>
<li>-> ë¶ˆìš© ê°œì²´ëª… ì œì™¸ í›„ DBì— insertí•˜ë©´ Table - related_word(keyword, related_word, flag, score, created_at)ì—ì„œ í™•ì¸ ê°€ëŠ¥</li>
<li>1. ì±—ì§€í”¼í‹° ì‚¬ì´íŠ¸ ui í…ŒìŠ¤íŠ¸ -> ì¸í’‹ ì•„ì›ƒí’‹ í”„ë¡¬í”„íŠ¸ ì—‘ì…€ì´ë‚˜ í”¼í”¼í‹°</li>
<li>table: related_wordì— keyword='æ”¹å'ì´ ë“¤ì–´ê°€ì„œ ì‚­ì œí•´ì•¼í•¨~</li>
<li>í•­ì²´ì˜ì•½í’ˆì€ êµ­ë¦½ë³´ê±´ì—°êµ¬ì›ê³¼ êµ­ë‚´ê¸°ì—…(ì…€íŠ¸ë¦¬ì˜¨)ì´ ê³µë™ì—°êµ¬ ì§„í–‰ ì¤‘ìœ¼ë¡œ, ì—°ë‚´ ì„ìƒì‹œí—˜ ì§„ì…ì„ ëª©í‘œë¡œ í•˜ì—¬ ë¹ ë¥´ë©´ ë‚´ë…„ ì¤‘ìœ¼ë¡œ ì¶œì‹œê°€ ê°€ëŠ¥í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°,</li>
<li>1.	db > table : file_summary_mnstr  / columns : file_id, ext_summary 10,000ê±´ ì¶”ì¶œ (ìµœì‹  ë‚ ì§œë¶€í„°~)</li>
<li>ì…€ë ˆë‹ˆì›€ ì‚¬ìš©ë²• ì—…ë°ì´íŠ¸ ì°¸ê³ ì‚¬ì´íŠ¸. .</li>
</ul>
</section>
<section class="container section prose" id="mermaid-diagram-generation-pipeline">
<h2>Mermaid Diagram Generation Pipeline</h2>
<p><strong>ê¸°ê°„:</strong> 2023.03.17 â€“ 2025.10.17 Â· <strong>íŒŒì¼ ìˆ˜:</strong> 77</p>
<p><strong>ì—­í• :</strong> ë Œë”ë§ ì˜¤ë¥˜ ìë™ ê²€ì¶œ, ì¬í”„ë¡¬í”„íŠ¸/ì •ê·œí™” ë£¨í‹´, íƒ€ì… ì¶”ë¡  ê·œì¹™ ì œì‘</p>
<p><strong>ê¸°ìˆ  ìŠ¤íƒ:</strong> Mermaid, OpenAI API, PIL, Python, Regex</p>
<p><strong>ì„±ê³¼:</strong> Fence/ë¬¸ë²• ì˜¤ë¥˜ ê°ì†Œ, íƒ€ì…ë³„ ì •í™•ë„ ê°œì„ </p>
<ul>
<li><strong>ìƒìœ„ í‚¤ì›Œë“œ:</strong> mermaidÃ—229, ì°¨íŠ¸Ã—126, pieÃ—118, xychartÃ—91, flowchartÃ—86, ë‹¤ì´ì–´ê·¸ë¨Ã—83, diagramÃ—82</li>
</ul>
<h3>ìƒì„¸ ë©”ëª¨(ë°œì·Œ)</h3><ul>
<li>* êµ¬ê¸€í”Œë ˆì´ ìµœê³  ë§¤ì¶œ ì°¨íŠ¸ëŠ” ëª¨ë°”ì¼ ê²Œì„ì˜ í¥í–‰ì—¬ë¶€ë¥¼ ë³´ì—¬ì£¼ëŠ” ì£¼ìš” ì§€í‘œë‹¤.</li>
<li>Recipient</li>
<li>kiwipiepy                 0.16.2                   pypi_0    pypi</li>
<li>kiwipiepy-model       0.16.0                   pypi_0    pypi</li>
<li>from kiwipiepy import Kiwi</li>
<li>prompt.messages[0].prompt.template = "You are an assistant for make some question-answering datasets. Use the following pieces of retrieved context to make datasets.\nQuestion: {question} \nContext: {â€¦</li>
<li>prompt.messages[0].prompt.template = "You are an assistant for make some question-answering datasets. Use the following pieces of retrieved context to make datasets.\nQuestion: {question} \nContext: {â€¦</li>
<li>prompt.messages[0].prompt.template = "You are an assistant for make some question-answering datasets. Use the following pieces of retrieved context to make datasets.\nQuestion: {question} \nContext: {â€¦</li>
<li>ì˜ë£Œì§„ì€ í•µì‹¬ ê°œë…ì„ ì„¤ëª…í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ê·¸ë¦¼  ë‹¤ì´ì–´ê·¸ë¨  ë˜ëŠ” ì°¨íŠ¸ì™€ ê°™ì€ ì„¤ëª…ì„ ì¶”ê°€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</li>
<li>ë˜í•œ ê¸°ë‹¨ ëª¨ì„œë¦¬ì— ìˆëŠ” ë„¤ ê°œì˜ ë¯¸ë‚˜ë ›ì€ ì´ìŠ¬ëŒ ê±´ì¶•ì˜ íŠ¹ì§•ì…ë‹ˆë‹¤.ì¸ë„ì˜ ì˜í–¥ì€ ì°¨íŠ¸ë¦¬(ë” ëª¨ì–‘ì˜ íŒŒë¹Œë¦¬ì˜¨) ì—°ê½ƒ ëª¨í‹°í”„ì™€ í”¼ì—íŠ¸ë¼ ë‘ë¼ ê¸°ë²• ì¦‰ ë°˜ê·€ì„(ë°˜ê·€ì„)ì„ ì„ì¬ ê¸°ì´ˆì— ì‚½ì…í•˜ì—¬ ë³µì¡í•œ ê½ƒ ë¬´ëŠ¬ë¥¼ ë§Œë“œëŠ” ì¥ì‹ ê¸°ë²•ì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.íƒ€ì§€ë§ˆí• ì˜ ê±´ì¶• ê¸°ìˆ ë„ ë†€ë¼ì› ìŠµë‹ˆë‹¤.</li>
</ul>
</section>
<section class="container section prose" id="qwen-series-fine-tuning-qwen2-5-vl-qwen3-vl-">
<h2>Qwen-series Fine-Tuning (Qwen2.5-VL / Qwen3-VL)</h2>
<p><strong>ê¸°ê°„:</strong> 2023.04.14 â€“ 2025.10.17 Â· <strong>íŒŒì¼ ìˆ˜:</strong> 366</p>
<p><strong>ì—­í• :</strong> Attention/í† í° ì‹œê°í™”, QLoRA ì‹¤í—˜/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, VLM íŒŒì¸íŠœë‹ ì„¤ê³„, ì»¤ë¦¬í˜ëŸ¼/ë¡œìŠ¤ ë§ˆìŠ¤í‚¹</p>
<p><strong>ê¸°ìˆ  ìŠ¤íƒ:</strong> ClearML, DeepSpeed, LoRA/QLoRA, PyTorch, Qwen2.5-VL, Qwen3-VL, Transformers, vLLM</p>
<p><strong>ì„±ê³¼:</strong> Vision Prior ê°•í™”, 32B ëª¨ë¸ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ êµ¬ì¶•</p>
<ul>
<li><strong>ìƒìœ„ í‚¤ì›Œë“œ:</strong> clearmlÃ—3789, qwenÃ—1769, loraÃ—1245, qwen2.5Ã—928, deepspeedÃ—252, qwen2_5Ã—185, vllmÃ—146, attentionÃ—138, projectorÃ—99, qwen3Ã—58, freezeÃ—36, qloraÃ—36</li>
</ul>
<h3>ìƒì„¸ ë©”ëª¨(ë°œì·Œ)</h3><ul>
<li>{"instruction": "What is a console war in video games?", "context": "In the video game industry, a console war describes the competition between two or more video game console manufacturers in trying â€¦</li>
<li>tactics by each company to try to gain control of the marketplace, and ended around 1995 when a new player, Sony, entered and disrupted the console space.\n\nThe United States video game industry suffâ€¦</li>
<li>drwxr-xr-x.  9 aisearch aisearch        4096  8ì›” 21 17:03 alpaca-lora</li>
<li>-rw-rw-r--.  1 aisearch aisearch    99256109  6ì›” 20 10:08 notebooks.lora.tar.gz</li>
<li>alpaca-lora                                                    latest                     d9d48ca7aee4   3 months ago   24.4GB</li>
<li>alpaca-lora                                                    latest                     d9d48ca7aee4   3 months ago   24.4GB</li>
<li>aisearch@urpaigpu1:~$ alpaca-lora                                                    latest                     d9d48ca7aee4   3 months ago   24.4GB</li>
<li>alpaca-lora: command not found</li>
<li>aisearch@urpaigpu1:~$ alpaca-lora                                                    latest                     d9d48ca7aee4   3 months ago   24.4GB</li>
<li>alpaca-lora: command not found</li>
</ul>
</section>
<section class="container section prose" id="any-to-any-embedding-retrieval">
<h2>Any-to-Any Embedding & Retrieval</h2>
<p><strong>ê¸°ê°„:</strong> 2023.09.04 â€“ 2025.10.17 Â· <strong>íŒŒì¼ ìˆ˜:</strong> 121</p>
<p><strong>ì—­í• :</strong> Query-centric í‰ê°€, ì„¸ê·¸ë¨¼íŠ¸ ìŠ¤í‚¤ë§ˆ ì„¤ê³„, ì„ë² ë”©/ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸</p>
<p><strong>ê¸°ìˆ  ìŠ¤íƒ:</strong> FAISS, NumPy, Pandas, Python, Transformers</p>
<p><strong>ì„±ê³¼:</strong> ê²€ìƒ‰ ì •í™•ë„/ì†ë„ ê°œì„ </p>
<ul>
<li><strong>ìƒìœ„ í‚¤ì›Œë“œ:</strong> embeddingÃ—361, similarityÃ—81, faissÃ—77, retrievalÃ—63, ì„¸ê·¸ë¨¼íŠ¸Ã—51, bbox_normÃ—31, query-centricÃ—12, indexflatipÃ—11</li>
</ul>
<h3>ìƒì„¸ ë©”ëª¨(ë°œì·Œ)</h3><ul>
<li>https://www.elastic.co/search-labs/how-to-deploy-nlp-text-embeddings-and-vector-search</li>
<li>https://www.elastic.co/kr/blog/how-to-deploy-nlp-text-embeddings-and-vector-search</li>
<li>https://www.unite.ai/ko/what-is-vector-similarity-search-how-is-it-useful/</li>
<li>ì„ë² ë”© ë²¡í„° ìƒì„± í›„ ë§¤í•‘í•˜ê¸° (id, document_key, embedding_vector)</li>
<li>ì„ë² ë”© ë²¡í„° ìƒì„± í›„ ë§¤í•‘í•˜ê¸° (id, document_key, embedding_vector)</li>
<li>query_embeddings</li>
<li>"cosine_similarity": {</li>
<li>"cosine_similarity": {</li>
<li>query_embeddings</li>
<li>https://www.elastic.co/kr/blog/how-to-deploy-nlp-text-embeddings-and-vector-search</li>
</ul>
</section>
<section class="container section prose" id="fastvithd-qwen-fusion">
<h2>FastViTHD + Qwen Fusion</h2>
<p><strong>ê¸°ê°„:</strong> 2024.05.13 â€“ 2025.10.17 Â· <strong>íŒŒì¼ ìˆ˜:</strong> 34</p>
<p><strong>ì—­í• :</strong> Attention/í† í° ì‹œê°í™”, Fusion ì•„í‚¤í…ì²˜ ì„¤ê³„, Projector/PE ì£¼ì… ì‹¤í—˜, QLoRA ì‹¤í—˜/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, VLM íŒŒì¸íŠœë‹ ì„¤ê³„, ì»¤ë¦¬í˜ëŸ¼/ë¡œìŠ¤ ë§ˆìŠ¤í‚¹, í•´ìƒë„ ë²„í‚· ìº˜ë¦¬ë¸Œë ˆì´ì…˜</p>
<p><strong>ê¸°ìˆ  ìŠ¤íƒ:</strong> ClearML, DeepSpeed, FastViT, LoRA/QLoRA, Projection Layers, PyTorch, Qwen2.5-VL, Qwen3-32B, Qwen3-VL, Transformers, vLLM</p>
<p><strong>ì„±ê³¼:</strong> Vision Prior ê°•í™”, 32B ëª¨ë¸ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ êµ¬ì¶•, í”„ë¡œí† íƒ€ì… í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì™„ì„±</p>
<ul>
<li><strong>ìƒìœ„ í‚¤ì›Œë“œ:</strong> projectorÃ—99, vision encoderÃ—59, fusionÃ—35, fastvlmÃ—21, fastvithdÃ—18, apple-styleÃ—2, sin/cosÃ—1</li>
</ul>
<h3>ìƒì„¸ ë©”ëª¨(ë°œì·Œ)</h3><ul>
<li>{'text_eng': 'The works of what American author include  The Catcher in the Rye   a novel that has become synonymous with teenage rebellion?\nJ.D. Salinger\nWhat significant impact did J.D. Salinger sâ€¦</li>
<li>WARN[0000] /home/aisearch/clearml/datasets/document_parse/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion</li>
<li>WARN[0000] /home/aisearch/clearml/datasets/document_parse/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion</li>
<li>WARN[0000] /home/aisearch/clearml/datasets/document_parse/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion</li>
<li>(1) Vision Encoder</li>
<li>print(f"Input size to Vision Encoder: H={H}, W={W}")</li>
<li>ë¹„ì „ ì¸ì½”ë”(Vision Encoder): ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì´í•´í•˜ê³  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ ì–¸ì–´ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.</li>
<li>(1) Vision Encoder</li>
<li>print(f"Input size to Vision Encoder: H={H}, W={W}")</li>
<li>âœ… vision encoderëŠ” freeze</li>
</ul>
</section>
<footer class="site-footer">
  <div class="container">
    <div class="cols">
      <div>
        <h4>About this site</h4>
        <p>Nomod-inspired minimal portfolio. Built with plain HTML/CSS/JS and hosted on GitHub Pages.</p>
      </div>
      <div>
        <h4>Links</h4>
        <ul>
          <li><a href="https://github.com/geonmin0607" target="_blank" rel="noopener">GitHub</a></li>
          <li><a href="mailto:contact@example.com">Email</a></li>
        </ul>
      </div>
      <div>
        <h4>Location</h4>
        <p>Seoul, Korea (UTC+9)</p>
      </div>
    </div>
    <p class="copy">Â© 2025 GEONMIN LEE. All rights reserved.</p>
  </div>
</footer>
</body>
</html>
